{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Original Attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 2 sets of image data: </br>\n",
    "`Train_original` folder will have 4 folders and named as the shoes brand name. There are totally 10 images in each folder.</br>\n",
    "`Validation_original` folder have the same content as `Train_original` folder, and will be used to test the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3779 - accuracy: 0.5000 - val_loss: 7.1434 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 8.1711 - accuracy: 0.2500 - val_loss: 2.8807 - val_accuracy: 0.2500\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 3.6650 - accuracy: 0.3125 - val_loss: 2.3023 - val_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 2.0520 - accuracy: 0.3750 - val_loss: 1.5602 - val_accuracy: 0.2188\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.5079 - accuracy: 0.2500 - val_loss: 1.3453 - val_accuracy: 0.2812\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 1.3605 - accuracy: 0.2500 - val_loss: 1.3182 - val_accuracy: 0.2812\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 1.3412 - accuracy: 0.2188 - val_loss: 1.3178 - val_accuracy: 0.3438\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 1.3169 - accuracy: 0.3750 - val_loss: 1.2823 - val_accuracy: 0.4688\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 1.2862 - accuracy: 0.5000 - val_loss: 1.1989 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.2309 - accuracy: 0.7500 - val_loss: 1.1566 - val_accuracy: 0.7812\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 1.1791 - accuracy: 0.7812 - val_loss: 1.0543 - val_accuracy: 0.8125\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.0211 - accuracy: 0.7500 - val_loss: 1.1430 - val_accuracy: 0.4062\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 1.1508 - accuracy: 0.3750 - val_loss: 1.0415 - val_accuracy: 0.5938\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.9167 - accuracy: 0.6562 - val_loss: 0.8917 - val_accuracy: 0.6875\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.9512 - accuracy: 0.6250 - val_loss: 0.7266 - val_accuracy: 0.8125\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.6707 - accuracy: 0.8438 - val_loss: 0.6172 - val_accuracy: 0.7812\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6580 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.4524 - accuracy: 0.8750 - val_loss: 0.5534 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.4177 - accuracy: 0.9062 - val_loss: 0.3956 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.1471 - accuracy: 0.8750 - val_loss: 0.4629 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.4993 - accuracy: 0.7750 - 234ms/epoch - 117ms/step\n",
      "\n",
      "Test accuracy: 0.7749999761581421\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define parameters\n",
    "input_shape = (150, 150, 3)  # Image dimensions\n",
    "num_classes = 4  # Nike, Adidas, Puma, Other\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "train_data_dir = '../../data/train_original'\n",
    "validation_data_dir = '../../data/validation_original'\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model definition\n",
    "original_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Conv2D(128, (3, 3), activation='relu'),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "original_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = original_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "original_model.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = original_model.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Optimization Attempt #1) </br>\n",
    "- Adding 1 more Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3868 - accuracy: 0.2812 - val_loss: 1.3510 - val_accuracy: 0.2812\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.5189 - accuracy: 0.1250 - val_loss: 1.3426 - val_accuracy: 0.3125\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.3734 - accuracy: 0.2500 - val_loss: 1.3551 - val_accuracy: 0.3438\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.3731 - accuracy: 0.3750 - val_loss: 1.3604 - val_accuracy: 0.3750\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 1.3554 - accuracy: 0.4062 - val_loss: 1.2989 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 1.3170 - accuracy: 0.5000 - val_loss: 1.2463 - val_accuracy: 0.6250\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 1.2775 - accuracy: 0.5312 - val_loss: 1.1333 - val_accuracy: 0.6875\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 1.1710 - accuracy: 0.5938 - val_loss: 1.0689 - val_accuracy: 0.6875\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.0290 - accuracy: 0.5000 - val_loss: 1.0277 - val_accuracy: 0.5938\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.9793 - accuracy: 0.6250 - val_loss: 0.8448 - val_accuracy: 0.7188\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 1.0071 - accuracy: 0.5625 - val_loss: 0.7172 - val_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.7552 - accuracy: 0.7812 - val_loss: 0.7244 - val_accuracy: 0.8125\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.6663 - accuracy: 0.8438 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.8207 - accuracy: 0.6250 - val_loss: 1.3730 - val_accuracy: 0.4688\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.6635 - accuracy: 0.2500 - val_loss: 0.4222 - val_accuracy: 0.9062\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.4503 - accuracy: 0.9062 - val_loss: 0.6304 - val_accuracy: 0.7812\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.7294 - accuracy: 0.7812 - val_loss: 0.7986 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3491 - accuracy: 0.8750 - val_loss: 0.8614 - val_accuracy: 0.6562\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.9843 - accuracy: 0.7500 - val_loss: 0.7837 - val_accuracy: 0.6875\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5578 - accuracy: 0.8750 - val_loss: 0.7865 - val_accuracy: 0.6875\n",
      "2/2 - 0s - loss: 0.5452 - accuracy: 0.8250 - 220ms/epoch - 110ms/step\n",
      "\n",
      "Test accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "optimization_model_1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimization_model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = optimization_model_1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "optimization_model_1.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = original_model.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Optimization Attempt #2) </br>\n",
    "- Adding 10 more images to each of the brands for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 images belonging to 4 classes.\n",
      "Found 80 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 4s 1s/step - loss: 1.7941 - accuracy: 0.1875 - val_loss: 1.4170 - val_accuracy: 0.2344\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 1.3921 - accuracy: 0.2353 - val_loss: 1.3721 - val_accuracy: 0.2500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 642ms/step - loss: 1.3898 - accuracy: 0.2353 - val_loss: 1.3698 - val_accuracy: 0.2969\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 1.3623 - accuracy: 0.2941 - val_loss: 1.3492 - val_accuracy: 0.2656\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 655ms/step - loss: 1.3841 - accuracy: 0.2353 - val_loss: 1.3423 - val_accuracy: 0.2969\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 1.3297 - accuracy: 0.4375 - val_loss: 1.2752 - val_accuracy: 0.7188\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 1.2947 - accuracy: 0.6275 - val_loss: 1.1670 - val_accuracy: 0.6406\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 1.1672 - accuracy: 0.5938 - val_loss: 1.0178 - val_accuracy: 0.6406\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 1.0683 - accuracy: 0.5686 - val_loss: 0.9001 - val_accuracy: 0.6875\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.9660 - accuracy: 0.5938 - val_loss: 0.8455 - val_accuracy: 0.7031\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 0.8463 - accuracy: 0.7059 - val_loss: 0.8872 - val_accuracy: 0.6094\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 0.9205 - accuracy: 0.6863 - val_loss: 0.8995 - val_accuracy: 0.6406\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.7722 - accuracy: 0.7255 - val_loss: 0.6935 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 638ms/step - loss: 0.6126 - accuracy: 0.7500 - val_loss: 0.6990 - val_accuracy: 0.7188\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 762ms/step - loss: 0.7383 - accuracy: 0.7059 - val_loss: 0.5434 - val_accuracy: 0.7969\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 650ms/step - loss: 0.6594 - accuracy: 0.7500 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 0.7178 - accuracy: 0.7255 - val_loss: 0.5482 - val_accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 659ms/step - loss: 0.5516 - accuracy: 0.8235 - val_loss: 0.5032 - val_accuracy: 0.8125\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 0.4699 - accuracy: 0.8431 - val_loss: 0.3806 - val_accuracy: 0.8906\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.3128 - accuracy: 0.8824 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
      "3/3 - 0s - loss: 0.3169 - accuracy: 0.8875 - 447ms/epoch - 149ms/step\n",
      "\n",
      "Test accuracy: 0.887499988079071\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '../../data/train_extend'\n",
    "validation_data_dir = '../../data/validation_extend'\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model definition\n",
    "optimization_model_2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimization_model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = optimization_model_2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "optimization_model_2.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = optimization_model_2.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n",
      "Predicted Brand: Nike\n",
      "Confidence: 0.9603383\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('shoe_brand_classifier.h5')\n",
    "\n",
    "# Function to predict the brand of a given image\n",
    "def predict_brand(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Convert to batch format (1, height, width, channels)\n",
    "    img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "\n",
    "    # return prediction \n",
    "    # Decode the prediction\n",
    "    brands = ['Adidas','Nike','Other','Puma' ]\n",
    "    predicted_brand = brands[np.argmax(prediction)]\n",
    "\n",
    "    # Print the prediction\n",
    "    print(\"Predicted Brand:\", predicted_brand)\n",
    "    print(\"Confidence:\", prediction[0][np.argmax(prediction)])\n",
    "\n",
    "# Test the model with a new image\n",
    "image_path = 'data/test/21.png' \n",
    "predict_brand(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
